# Market Simulator Development Plan

## Part 1: Core Invariants

These are the architectural commitments that cannot be violated without requiring significant rework:

**1. Top-Down Recursion is Inviolable**
The system must always drive price from larger timeframes to smaller ones, never the reverse. This isn't a tunable parameter—it's the fundamental generative principle. Every design decision must preserve the invariant that monthly swings constrain daily swings, which constrain hourly swings, which constrain minute bars. If you find yourself propagating information upward, you've broken the architecture.

**2. Levels Are Derived, Not Stored**
The Fibonacci-based levels (0, 0.382, 0.5, 0.618, 1, 1.382, 1.5, 1.618, 2, etc.) must always be computed from reference swings, never cached as absolute prices. When a swing completes or a new reference is established, all dependent levels shift. A system that stores "support at 650" rather than "support at 0.618 of swing X" will break under any structural change.

**3. Reference Swing Selection is Contextual**
Multiple valid reference swings can coexist. The selection criteria (large, impulsive, early) must be applied dynamically based on the current price position and timeframe. Hardcoding a single reference swing or making selection static will produce unrealistic behavior.

**4. Triggers Accelerate but Don't Determine**
News events can only accelerate or delay moves that are structurally primed. A trigger cannot force the market to do something the structural rules forbid. The architecture must enforce this separation: the structural model determines what *can* happen; the trigger model determines *when*.

**5. OHLC Bars Must Be Internally Consistent**
Every generated bar must satisfy: Low ≤ Open ≤ High, Low ≤ Close ≤ High. More subtly, the *path* within a bar matters for lower timeframes. A 1-minute bar aggregated from tick-level logic must tell a coherent story that respects structural rules.

**6. Timeframe Aggregation Must Preserve Structural Properties**
If minute bars are generated correctly, aggregating them to hourly/daily/weekly must *automatically* satisfy the structural rules at those timeframes. If you need post-hoc corrections at higher timeframes, your minute-level generation is wrong.

---

## Part 2: Primary Failure Modes

These are the predictable ways this system will break:

**1. Circular Dependencies in Recursion**
Junior engineers will try to make smaller swings "inform" larger ones, creating circular dependencies. Watch for any code that queries lower-timeframe state to make higher-timeframe decisions.

**2. Floating-Point Level Comparison**
"Is price at the 1.618 level?" requires fuzzy comparison. Engineers will write `price == level_1618` which will never be true. Every level check needs tolerance bands, and those bands must scale with timeframe.

**3. Reference Swing Explosion**
Without proper pruning, the number of active reference swings will grow unboundedly. Engineers will either keep too many (memory/performance death) or too few (loss of structural context). Need clear expiration rules.

**4. Trigger-Structure Desynchronization**
The trigger generator and price model will drift out of sync. A trigger fires, the price model responds, but the trigger model doesn't know the structural context changed. Need explicit state synchronization points.

**5. Timeframe Boundary Artifacts**
Midnight UTC, market open/close, month boundaries—these create discontinuities that junior engineers will handle inconsistently. Expect off-by-one errors in aggregation and strange behavior at session boundaries.

**6. The "It Looks Right" Trap**
Engineers will tune parameters until the output *looks* reasonable on a single run, without understanding *why* it looks right. Need statistical validation across many runs, not just visual inspection.

**7. State Management in Recursion**
The recursive structure requires careful state management. Engineers will either pass too much state (coupling explosion) or too little (lost context). The boundary between "structural context" and "local generation state" must be crisp.

**8. Premature Optimization**
Generating years of 1-minute data is computationally expensive. Engineers will try to optimize before correctness is established, introducing subtle bugs that take weeks to find.

---

## Part 3: Task Decomposition

### Module A: Core Data Structures

#### A1: Price and Time Primitives
**Description:** Define the fundamental types: `Price` (decimal, quantization-aware), `Timestamp` (UTC with timezone mapping), `Bar` (OHLC + timestamp + volume placeholder). Implement quantization rules (0.25 for indices, 0.01 for stocks).

**Acceptance Criteria:**
- Price arithmetic preserves quantization
- Timestamps correctly convert between UTC/PST/EST
- Bars reject invalid OHLC relationships at construction time
- Unit tests cover edge cases (midnight crossings, quantization rounding)

**Dependencies:** None

**Risks:** Quantization rounding errors; timezone DST handling

**Review:** Batch review acceptable

---

#### A2: Level Calculator
**Description:** Given a swing (high price, low price, direction), compute all structural levels: -0.1, 0, 0.1, 0.382, 0.5, 0.618, 1, 1.1, 1.382, 1.5, 1.618, 2. Return as a structured object with level type annotations (decision zone, liquidity void, exhaustion, etc.).

**Acceptance Criteria:**
- Levels computed correctly for both bull and bear swings
- Level type annotations match spec (1.382-1.618 = decision zone, etc.)
- Tolerance bands scale appropriately with swing size
- Works with quantized prices

**Dependencies:** A1

**Risks:** Getting the direction convention wrong (bull swing = prior downswing)

**Review:** Architect review required—this is foundational

---

#### A3: Swing Detector
**Description:** Given a series of bars, identify swing highs and swing lows. A swing high is a bar whose high exceeds N bars on either side. Parameterize N by timeframe.

**Acceptance Criteria:**
- Correctly identifies swings in known test data
- Handles edge cases (start/end of series, equal highs)
- Parameterization works across timeframes
- Returns swing objects with timestamp, price, type

**Dependencies:** A1

**Risks:** Off-by-one in lookback window; handling ties

**Review:** Batch review acceptable

---

#### A4: Reference Swing Selector
**Description:** Given current price and a set of swings, select valid reference swings per the spec: for bullish reference, high precedes low and price > 0.382 retracement. Implement the recursion outward to find all valid references. Score by size, impulsiveness (move speed), and recency.

**Acceptance Criteria:**
- Correctly filters valid references by direction and position
- Recursion terminates at largest valid swing
- Scoring function produces reasonable rankings
- Returns multiple candidates when appropriate

**Dependencies:** A2, A3

**Risks:** Recursion termination conditions; handling no valid references

**Review:** Architect review required—this determines structural context

---

### Module B: Structural Price Model

#### B1: State Machine for Single Swing
**Description:** Model the lifecycle of a single swing: inception → extension (toward 2x) → exhaustion → pullback. Define states, valid transitions, and the conditions that trigger each transition.

**Acceptance Criteria:**
- States cover full lifecycle per spec
- Transitions are deterministic given structural inputs
- Invalid transitions are rejected with clear errors
- State can be serialized/deserialized for debugging

**Dependencies:** A2

**Risks:** Missing edge states; overly complex state graph

**Review:** Architect review required—this is the core behavioral model

---

#### B2: Multi-Timeframe Swing Container
**Description:** Data structure that holds active swings across timeframes (monthly, daily, hourly, minute). Enforces top-down constraint: lower timeframes can query higher, not vice versa.

**Acceptance Criteria:**
- Clean API for querying structural context at any timeframe
- Prevents upward information flow (compile-time or runtime check)
- Efficient updates when swings complete or new ones form
- Memory bounded with clear expiration policy

**Dependencies:** B1

**Risks:** Allowing upward queries "just this once"; unbounded growth

**Review:** Architect review required—enforces core invariant

---

#### B3: Level Stacking Calculator
**Description:** Given active swings across timeframes, compute where levels overlap. Quantify alignment (explosive move expected) vs. opposition (grinding move expected).

**Acceptance Criteria:**
- Correctly identifies overlapping levels within tolerance
- Alignment score reflects number of agreeing vs. opposing levels
- Output usable by price generation logic
- Performance acceptable with many active swings

**Dependencies:** A2, B2

**Risks:** Tolerance band calibration; performance with many swings

**Review:** Batch review acceptable

---

#### B4: Frustration Detector
**Description:** Detect when price repeatedly stalls within 5% of a key level. Track stall count and duration. Determine when frustration triggers symmetric retracement bias.

**Acceptance Criteria:**
- Correctly counts stalls at each level
- Threshold for "frustrated" is configurable
- Outputs the symmetric target level
- Distinguishes highest-swing frustration (measured move rule) from others

**Dependencies:** A2, B2

**Risks:** Defining "stall" precisely; resetting frustration after resolution

**Review:** Batch review acceptable

---

#### B5: Measured Move Calculator
**Description:** When a level fails cleanly at the highest timeframe, compute the measured move target (equal distance in opposite direction).

**Acceptance Criteria:**
- Correctly identifies "clean" failure (distinguish from wick)
- Computes target correctly
- Integrates with level stacking as a new attractor
- Handles nested measured moves

**Dependencies:** A2, B2

**Risks:** Defining "clean failure"; interaction with existing levels

**Review:** Batch review acceptable

---

### Module C: Trigger Model

#### C1: Trigger Event Structure
**Description:** Define the trigger event type: timestamp, polarity (-1 to +1 continuous), intensity (0 to 1, long-tailed), scheduled flag. No semantic content needed.

**Acceptance Criteria:**
- Clean data structure with validation
- Serializable for replay/debugging
- Timestamp precision sufficient for minute bars

**Dependencies:** A1

**Risks:** None significant

**Review:** Batch review acceptable

---

#### C2: Stochastic Trigger Generator
**Description:** Generate a stream of trigger events. Base distribution is approximately normal with configurable long tail. Scheduled events at known timestamps (market open, hypothetical CPI days). Unscheduled events at random intervals.

**Acceptance Criteria:**
- Distribution matches spec (mostly mild, occasionally extreme)
- Scheduled events appear at correct times
- Event rate is configurable
- Generator is seedable for reproducibility

**Dependencies:** C1

**Risks:** Getting the tail weight wrong; clustering of events

**Review:** Batch review acceptable

---

#### C3: Trigger-Structure Interaction Rules
**Description:** Given current structural state and a trigger, determine the response: acceleration, delay, noise, or reversal. Codify the rules from spec (aligned trigger = acceleration; misaligned = noise or delay).

**Acceptance Criteria:**
- All interaction types from spec are implemented
- Clear decision tree or rules engine
- Output is a "price impulse" that the generator consumes
- Edge cases handled (trigger at exhaustion, trigger in void)

**Dependencies:** B1, C1

**Risks:** Oversimplifying the interaction; missing edge cases

**Review:** Architect review required—this bridges the two models

---

### Module D: Price Generation Engine

#### D1: Single-Bar Generator
**Description:** Given structural context and an optional trigger impulse, generate a single 1-minute OHLC bar. Must respect level attractions, current swing state, and volatility expectations.

**Acceptance Criteria:**
- Generated bars are always valid (OHLC relationship)
- Bars respect quantization
- Volatility scales appropriately with context
- No trigger = small random move within current structure

**Dependencies:** B1, B2, B3, C3

**Risks:** Volatility calibration; respecting all constraints simultaneously

**Review:** Architect review required—this is the core generation logic

---

#### D2: Session-Aware Generation
**Description:** Extend D1 to handle market sessions: pre-market, regular hours, after-hours, closed. Different volatility and gap behavior for each.

**Acceptance Criteria:**
- Correctly identifies session from timestamp
- Gaps at market open are realistic
- Overnight moves respect structural context
- Weekend gaps handled

**Dependencies:** D1

**Risks:** Timezone bugs; session boundary off-by-ones

**Review:** Batch review acceptable

---

#### D3: Recursive Descent Generator
**Description:** The main generation loop. Start with monthly structural context, generate daily swings within it, generate hourly swings within daily, generate minute bars within hourly. Ensure each level constrains but doesn't over-determine the next.

**Acceptance Criteria:**
- Monthly structure correctly constrains daily
- Daily correctly constrains hourly
- Hourly correctly constrains minute
- Lower timeframes show more local volatility (per spec)
- Full month of data can be generated without errors

**Dependencies:** D1, D2, B2

**Risks:** Over-constraining lower timeframes; state synchronization across levels

**Review:** Architect review required—this is the architectural centerpiece

---

#### D4: Aggregation Validator
**Description:** Take generated minute bars, aggregate to higher timeframes, verify that structural rules are satisfied. This is a validation tool, not a correction tool—if it fails, the generation is broken.

**Acceptance Criteria:**
- Correct aggregation (OHLC rules for combining bars)
- Structural validation at each timeframe
- Clear error reporting when validation fails
- Performance acceptable for large datasets

**Dependencies:** D3, A3, B1

**Risks:** Validation logic diverging from generation logic

**Review:** Batch review acceptable

---

### Module E: Output and Debugging

#### E1: CSV/Parquet Output
**Description:** Write generated data in standard formats. Include metadata (generation parameters, seed, structural state snapshots).

**Acceptance Criteria:**
- Standard OHLC format readable by common tools
- Metadata preserved for reproducibility
- Efficient for large datasets
- Configurable output frequency (every N bars, end of run, etc.)

**Dependencies:** D3

**Risks:** None significant

**Review:** Batch review acceptable

---

#### E2: Visualization Scaffold
**Description:** Simple charting for visual inspection. Candlestick chart with overlaid structural levels. Must be fast to iterate—generate data, view chart, adjust parameters.

**Acceptance Criteria:**
- Displays candles correctly
- Overlays current reference swing levels
- Shows trigger events as markers
- Interactive zoom/pan for inspection
- Launches in < 2 seconds for typical dataset

**Dependencies:** D3, E1

**Risks:** Over-investing in visualization; matplotlib performance

**Review:** Batch review acceptable

---

#### E3: Statistical Validation Suite
**Description:** Beyond visual inspection: compute statistics that should match real markets. Return distributions, volatility clustering, autocorrelation structure, etc.

**Acceptance Criteria:**
- Suite of standard market statistics
- Comparison against known real-market baselines
- Clear pass/fail or similarity scores
- Runs automatically in CI

**Dependencies:** D3

**Risks:** Choosing wrong statistics; overfitting to statistics

**Review:** Batch review acceptable

---

### Module F: Integration and Hardening

#### F1: End-to-End Pipeline
**Description:** Single entry point that generates configurable amounts of data with specified parameters. Handles initialization, generation loop, output, and cleanup.

**Acceptance Criteria:**
- CLI with sensible defaults
- Configurable timeframe, duration, seed
- Progress reporting for long runs
- Graceful error handling

**Dependencies:** All D and E tasks

**Risks:** Configuration explosion; missing error cases

**Review:** Batch review acceptable

---

#### F2: Performance Profiling
**Description:** Profile the generator to identify bottlenecks. Target: generate 1 year of minute data in under 10 minutes.

**Acceptance Criteria:**
- Baseline performance measured
- Top 3 bottlenecks identified
- At least one optimization implemented
- Performance target met or gap quantified

**Dependencies:** F1

**Risks:** Premature optimization; breaking correctness for speed

**Review:** Batch review acceptable

---

#### F3: Reproducibility Verification
**Description:** Verify that same seed + parameters = same output. Identify and eliminate any sources of non-determinism.

**Acceptance Criteria:**
- Bit-identical output for same inputs
- All random sources seeded properly
- Floating-point determinism addressed
- CI test enforces this

**Dependencies:** F1

**Risks:** Hidden non-determinism (dict ordering, threading, etc.)

**Review:** Batch review acceptable

---

## Part 4: Task Sequencing

### Phase 1: Foundation (Week 1)
**Parallel tracks:**
- Track 1: A1 → A2 → A3 → A4
- Track 2: C1 → C2

**Rationale:** These have no interdependencies and establish the vocabulary for everything else. Validates that we can represent swings and triggers correctly before building behavior.

**Architect checkpoint:** Review A2 (Level Calculator) and A4 (Reference Swing Selector) before proceeding.

---

### Phase 2: Core Behavior (Weeks 2-3)
**Sequence:** B1 → B2 → [B3, B4, B5 in parallel]

**Rationale:** B1 (State Machine) must be right before anything else behavioral. B2 (Multi-Timeframe Container) enforces the core invariant. B3-B5 are independent utilities that consume the container.

**Architect checkpoint:** Review B1 and B2 before proceeding to generation.

---

### Phase 3: Integration Bridge (Week 3)
**Sequence:** C3 (Trigger-Structure Interaction)

**Rationale:** This is the riskiest piece—it bridges the two models. Must be reviewed carefully before generation work begins. Can proceed in parallel with B3-B5.

**Architect checkpoint:** Review C3 before any generation work.

---

### Phase 4: Generation (Weeks 4-5)
**Sequence:** D1 → D2 → D3 → D4

**Rationale:** Strictly sequential—each builds on the prior. D3 is the architectural centerpiece and will require iteration.

**Architect checkpoint:** Review D1 and D3. D3 may require multiple review cycles.

---

### Phase 5: Validation and Output (Week 5-6)
**Parallel tracks:**
- Track 1: E1 → E2
- Track 2: E3

**Rationale:** Output and visualization enable debugging; statistical validation enables rigor. Both needed but independent.

**Architect checkpoint:** None required—batch review acceptable.

---

### Phase 6: Hardening (Week 6+)
**Sequence:** F1 → [F2, F3 in parallel]

**Rationale:** Pipeline must exist before profiling or reproducibility work.

**Architect checkpoint:** None required—batch review acceptable.

---

## Part 5: The First Task

**Start with A2: Level Calculator.**

**Why this is the right starting point:**

1. **It's foundational but self-contained.** The level calculations (Fibonacci extensions and retracements from a swing) are the atomic unit of the entire system. Every other component depends on computing these correctly. But A2 has only one dependency (A1, which is trivial) and can be fully tested in isolation.

2. **It validates a key assumption.** The spec assumes these levels are meaningful and can be computed consistently. Building A2 first forces you to resolve ambiguities: What exactly is the "swing size" for a swing from 674 to 646? Is it 28 points, or do we compute it differently? Getting this wrong would propagate everywhere.

3. **It's small enough to complete in a day.** An engineer can have working, tested code by end of day one. This provides immediate momentum and a concrete artifact to discuss.

4. **It unblocks parallel work.** Once A2 exists, A3 and A4 can proceed. More importantly, the *interface* of A2 (how do you ask for levels? how are they represented?) establishes a pattern that B1-B5 will follow.

5. **It's the right level of difficulty.** Challenging enough that a junior engineer will learn something (handling both directions, getting tolerances right, testing edge cases), but not so hard that they'll get stuck.

**Guidance for the engineer:**

Start by writing the test cases first. Take the example from the spec: swing from 674 to 646 (28-point downswing, bullish reference). The 2x extension should be 702. Write tests for all the levels. Then implement until tests pass. Then add tests for a bearish reference. Then add tolerance band logic. Ship when tests are green and you can explain why each test exists.